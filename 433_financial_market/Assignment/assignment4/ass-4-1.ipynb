{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data = pd.read_csv('assignment4a.csv')\n",
    "data.date = pd.to_datetime(data.date)\n",
    "secs = ['Exxon Mobil', 'Procter & Gamble', 'Pfizer', 'Walmart ', 'Intel']\n",
    "rf = '30 Day T-Bill'\n",
    "\n",
    "r_premium = data[secs]\n",
    "for sec in secs:\n",
    "    r_premium[sec] -= data[rf]"
   ]
  },
  {
   "source": [
    "## 1-A\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_hat\n",
    "r_hat = pd.Series(index = secs)\n",
    "for sec in secs:\n",
    "    r_hat[sec] = r_premium[sec].mean()\n",
    "# cov_hat\n",
    "cov_hat = pd.DataFrame(columns = secs, index = secs)\n",
    "for sec in secs:\n",
    "    for sec2 in secs:\n",
    "        cov_hat[sec][sec2] = data[sec].cov(data[sec2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tangency portfolio is\n[[0.35981595]\n [0.11546475]\n [0.10449339]\n [0.28022511]\n [0.1400008 ]]\n"
     ]
    }
   ],
   "source": [
    "cov_inv = np.mat(cov_hat.values,dtype = 'float').I\n",
    "w = cov_inv@r_hat.values.reshape((5,1))\n",
    "w = w/w.sum()\n",
    "print('tangency portfolio is')\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tangency portfolio after rounding r is\n[[0.42794154]\n [0.3010659 ]\n [0.08517738]\n [0.04732312]\n [0.13849206]]\n"
     ]
    }
   ],
   "source": [
    "r_hat_round = round(r_hat*100)/100\n",
    "w_us_round = cov_inv@r_hat_round.values.reshape((5,1))\n",
    "w_round = w_us_round/w_us_round.sum()\n",
    "print('tangency portfolio after rounding r is')\n",
    "print(w_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "minimum variance portfolio is\n[[ 0.48408506]\n [ 0.31172185]\n [ 0.12538609]\n [ 0.08811868]\n [-0.00931167]]\n"
     ]
    }
   ],
   "source": [
    "w_mv = cov_inv.sum(axis = 1)\n",
    "w_mv = w_mv/w_mv.sum()\n",
    "print('minimum variance portfolio is')\n",
    "print(w_mv)"
   ]
  },
  {
   "source": [
    "## 1_B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tangency portfolio with identity variance is\n[[0.1325108 ]\n [0.12528056]\n [0.15007856]\n [0.27130118]\n [0.3208289 ]]\ntangency portfolio with identity variance after rounding r is\n[[0.16666667]\n [0.16666667]\n [0.16666667]\n [0.16666667]\n [0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "w_im = np.identity(5)@r_hat.values.reshape((5,1))\n",
    "w_im = w_im/w_im.sum()\n",
    "print('tangency portfolio with identity variance is')\n",
    "print(w_im)\n",
    "w_im_round = np.identity(5)@r_hat_round.values.reshape((5,1))\n",
    "w_im_round = w_im_round/w_im_round.sum()\n",
    "print('tangency portfolio with identity variance after rounding r is')\n",
    "print(w_im_round)"
   ]
  },
  {
   "source": [
    "\n",
    "## 1-C"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tangency portfolio using CAPM is\n[[0.23562901]\n [0.18876788]\n [0.39993247]\n [0.11516405]\n [0.06050659]]\n"
     ]
    }
   ],
   "source": [
    "r_m = 0.005\n",
    "beta = np.array([0.6,0.7,1.2,0.9,1.2])\n",
    "r_CAPM = pd.Series(data = beta * r_m, index = secs)\n",
    "w_CAPM = cov_inv@r_CAPM.values.reshape((5,1))\n",
    "w_CAPM = w_CAPM/w_CAPM.sum()\n",
    "print('tangency portfolio using CAPM is')\n",
    "print(w_CAPM)"
   ]
  },
  {
   "source": [
    "## 1-D"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tangency portfolio using Bayesian is\n[[0.18874911]\n [0.14995926]\n [0.20797496]\n [0.24974542]\n [0.20357126]]\n"
     ]
    }
   ],
   "source": [
    "r_bayesian = (r_CAPM + r_hat)/2\n",
    "sigma = np.mat(cov_hat.values).diagonal().mean()\n",
    "cov_bayesian = (cov_hat + sigma * np.identity(5))/2\n",
    "cov_bayesian_inv = np.mat(cov_bayesian.values,dtype = 'float').I\n",
    "w_baysian = cov_bayesian_inv@r_bayesian.values.reshape((5,1))\n",
    "w_baysian = w_baysian/w_baysian.sum()\n",
    "print('tangency portfolio using Bayesian is')\n",
    "print(w_baysian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_return = pd.Series()\n",
    "B_return = pd.Series()\n",
    "C_return = pd.Series()\n",
    "D_return = pd.Series()\n",
    "\n",
    "for i in range(5,47): #(1,47)\n",
    "    data_available = data.iloc[0:12*i,]\n",
    "    r_p = r_premium.iloc[0:12*i,]\n",
    "    r_p_next = r_premium.iloc[12*i:12*(i+1),]\n",
    "    # A: tangency portfolio using estimated r + estimated covariance\n",
    "    r_hat = pd.Series(index = secs)\n",
    "    for sec in secs:\n",
    "        r_hat[sec] = r_p[sec].mean()\n",
    "    cov_hat = pd.DataFrame(columns = secs, index = secs)\n",
    "    for sec in secs:\n",
    "        for sec2 in secs:\n",
    "            cov_hat[sec][sec2] = data_available[sec].cov(data_available[sec2])\n",
    "    cov_inv = np.mat(cov_hat.values,dtype = 'float').I\n",
    "    w = cov_inv@r_hat.values.reshape((5,1))\n",
    "    w = w/w.sum()\n",
    "    A_return = pd.concat([A_return,(w.A.reshape(5) * r_p_next).sum(axis = 1)])\n",
    "\n",
    "    # B: tangency portfolio with estimated r + identity variance\n",
    "    w_im = np.identity(5)@r_hat.values.reshape((5,1))\n",
    "    w_im = w_im/w_im.sum()\n",
    "    B_return = pd.concat([B_return,(w_im.reshape(5) * r_p_next).sum(axis = 1)])\n",
    "\n",
    "    # C: tangency portfolio with CAPM r + estimated variance\n",
    "    w_CAPM = cov_inv@r_CAPM.values.reshape((5,1))\n",
    "    w_CAPM = w_CAPM/w_CAPM.sum()\n",
    "    C_return = pd.concat([C_return,(w_CAPM.A.reshape(5) * r_p_next).sum(axis = 1)])\n",
    "\n",
    "    # D: tangency portfolio with Baysian r + variance\n",
    "    r_bayesian = (r_CAPM + r_hat)/2\n",
    "    sigma = np.mat(cov_hat.values).diagonal().mean()\n",
    "    cov_bayesian = (cov_hat + sigma * np.identity(5))/2\n",
    "    cov_bayesian_inv = np.mat(cov_bayesian.values,dtype = 'float').I\n",
    "    w_bayesian = cov_bayesian_inv@r_bayesian.values.reshape((5,1))\n",
    "    w_bayesian = w_bayesian/w_bayesian.sum()\n",
    "    D_return = pd.concat([D_return,(w_bayesian.A.reshape(5) * r_p_next).sum(axis = 1)])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.004643543972085544\n0.013298864775883493\n0.009232666775147245\n0.013328509257871995\n"
     ]
    }
   ],
   "source": [
    "print(A_return.mean())\n",
    "print(B_return.mean())\n",
    "print(C_return.mean())\n",
    "print(D_return.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.01723899711256686\n0.22553979460391807\n0.21835788218779653\n0.2269321249279514\n"
     ]
    }
   ],
   "source": [
    "print(A_return.mean()/ A_return.std())\n",
    "print(B_return.mean()/ B_return.std())\n",
    "print(C_return.mean()/ C_return.std())\n",
    "print(D_return.mean()/ D_return.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}